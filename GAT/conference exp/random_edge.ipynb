{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Understand Graph Attention Network\n",
        "=======================================\n",
        "\n",
        "**Authors:** `Hao Zhang <https://github.com/sufeidechabei/>`_, `Mufei Li\n",
        "<https://github.com/mufeili>`_, `Minjie Wang\n",
        "<https://jermainewang.github.io/>`_  `Zheng Zhang\n",
        "<https://shanghai.nyu.edu/academics/faculty/directory/zheng-zhang>`_\n",
        "\n",
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>The tutorial aims at gaining insights into the paper, with code as a mean\n",
        "    of explanation. The implementation thus is NOT optimized for running\n",
        "    efficiency. For recommended implementation, please refer to the `official\n",
        "    examples <https://github.com/dmlc/dgl/tree/master/examples>`_.</p></div>\n",
        "\n",
        "In this tutorial, you learn about a graph attention network (GAT) and how it can be \n",
        "implemented in PyTorch. You can also learn to visualize and understand what the attention \n",
        "mechanism has learned.\n",
        "\n",
        "The research described in the paper `Graph Convolutional Network (GCN) <https://arxiv.org/abs/1609.02907>`_,\n",
        "indicates that combining local graph structure and node-level features yields\n",
        "good performance on node classification tasks. However, the way GCN aggregates\n",
        "is structure-dependent, which can hurt its generalizability.\n",
        "\n",
        "One workaround is to simply average over all neighbor node features as described in\n",
        "the research paper `GraphSAGE\n",
        "<https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf>`_.\n",
        "However, `Graph Attention Network <https://arxiv.org/abs/1710.10903>`_ proposes a\n",
        "different type of aggregation. GAT uses weighting neighbor features with feature dependent and\n",
        "structure-free normalization, in the style of attention.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Introducing attention to GCN\n",
        "----------------------------\n",
        "\n",
        "The key difference between GAT and GCN is how the information from the one-hop neighborhood is aggregated.\n",
        "\n",
        "For GCN, a graph convolution operation produces the normalized sum of the node features of neighbors.\n",
        "\n",
        "\n",
        "$\\begin{align}h_i^{(l+1)}=\\sigma\\left(\\sum_{j\\in \\mathcal{N}(i)} {\\frac{1}{c_{ij}} W^{(l)}h^{(l)}_j}\\right)\\end{align}$\n",
        "\n",
        "\n",
        "where $\\mathcal{N}(i)$ is the set of its one-hop neighbors (to include\n",
        "$v_i $ in the set, simply add a self-loop to each node),\n",
        "$c_{ij}=\\sqrt{|\\mathcal{N}(i)|}\\sqrt{|\\mathcal{N}(j)|}$ is a\n",
        "normalization constant based on graph structure, $\\sigma$ is an\n",
        "activation function (GCN uses ReLU), and $W^{(l)}$ is a shared\n",
        "weight matrix for node-wise feature transformation. Another model proposed in\n",
        "`GraphSAGE\n",
        "<https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf>`_\n",
        "employs the same update rule except that they set\n",
        "$c_{ij}=|\\mathcal{N}(i)|$.\n",
        "\n",
        "GAT introduces the attention mechanism as a substitute for the statically\n",
        "normalized convolution operation. Below are the equations to compute the node\n",
        "embedding $h_i^{(l+1)}$ of layer $l+1$ from the embeddings of\n",
        "layer $l$.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/gat/gat.png)\n",
        "$\n",
        "\\begin{align}\\begin{align}\n",
        "  z_i^{(l)}&=W^{(l)}h_i^{(l)}, &(1)\\\\\n",
        "  e_{ij}^{(l)}&=\\text{LeakyReLU}(\\vec a^{(l)^T}(z_i^{(l)}||z_j^{(l)})) \\text{, Shape is edges * 1} &(2)\\\\\n",
        "  \\alpha_{ij}^{(l)}&=\\frac{\\exp(e_{ij}^{(l)})}{\\sum_{k\\in \\mathcal{N}(i)}^{}\\exp(e_{ik}^{(l)})}, &(3)\\\\\n",
        "  h_i^{(l+1)}&=\\sigma\\left(\\sum_{j\\in \\mathcal{N}(i)} {\\alpha^{(l)}_{ij} z^{(l)}_j }\\right), &(4)\\\\\n",
        "  \\end{align}\\end{align}\n",
        "$\n",
        "\n",
        "Explanations:\n",
        "\n",
        "\n",
        "* Equation (1) is a linear transformation of the lower layer embedding $h_i^{(l)}$\n",
        "  and $W^{(l)}$ is its learnable weight matrix.\n",
        "* Equation (2) computes a pair-wise *un-normalized* attention score between two neighbors.\n",
        "  Here, it first concatenates the $z$ embeddings of the two nodes, where $||$\n",
        "  denotes concatenation, then takes a dot product of it and a learnable weight vector\n",
        "  $\\vec a^{(l)}$, and applies a LeakyReLU in the end. This form of attention is\n",
        "  usually called *additive attention*, contrast with the dot-product attention in the\n",
        "  Transformer model.\n",
        "* Equation (3) applies a softmax to normalize the attention scores on each node's\n",
        "  incoming edges.\n",
        "* Equation (4) is similar to GCN. The embeddings from neighbors are aggregated together,\n",
        "  scaled by the attention scores.\n",
        "\n",
        "There are other details from the paper, such as dropout and skip connections.\n",
        "For the purpose of simplicity, those details are left out of this tutorial. To see more details, \n",
        "download the `full example <https://github.com/dmlc/dgl/blob/master/examples/pytorch/gat/gat.py>`_.\n",
        "In its essence, GAT is just a different aggregation function with attention\n",
        "over features of neighbors, instead of a simple mean aggregation.\n",
        "\n",
        "GAT in DGL\n",
        "----------\n",
        "\n",
        "DGL provides an off-the-shelf implementation of the GAT layer under the ``dgl.nn.<backend>``\n",
        "subpackage. Simply import the ``GATConv`` as the follows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dgl.nn.pytorch import GATConv\n",
        "from dgl.data import CoraGraphDataset\n",
        "import dgl\n",
        "from dgl.data.utils import load_graphs\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from copy import deepcopy\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from os import _exit\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "\n",
        "from randomedge import *\n",
        "from eval import *\n",
        "from gat import *\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Readers can skip the following step-by-step explanation of the implementation and\n",
        "jump to the `Put everything together`_ for training and visualization results.\n",
        "\n",
        "To begin, you can get an overall impression about how a ``GATLayer`` module is\n",
        "implemented in DGL. In this section, the four equations above are broken down \n",
        "one at a time.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This is showing how to implement a GAT from scratch.  DGL provides a more\n",
        "   efficient :class:`builtin GAT layer module <dgl.nn.pytorch.conv.GATConv>`.</p></div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = ''\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class GATLayer(nn.Module):\n",
        "    def __init__(self, g, in_dim, out_dim):\n",
        "        super(GATLayer, self).__init__()\n",
        "        self.g = g.to(device)\n",
        "        # equation (1)\n",
        "        self.fc = nn.Linear(in_dim, out_dim, bias=False, device = device)\n",
        "        # equation (2)\n",
        "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False, device = device)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Reinitialize learnable parameters.\"\"\"\n",
        "        gain = nn.init.calculate_gain('relu')\n",
        "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
        "\n",
        "    def edge_attention(self, edges):\n",
        "        # edge UDF for equation (2)\n",
        "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1).to(device = device)\n",
        "        a = self.attn_fc(z2)\n",
        "        \n",
        "        return {'e': F.leaky_relu(a).to(device = device)}\n",
        "\n",
        "    def message_func(self, edges):\n",
        "        # message UDF for equation (3) & (4)\n",
        "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
        "\n",
        "    def reduce_func(self, nodes):\n",
        "        # reduce UDF for equation (3) & (4)\n",
        "        # equation (3)\n",
        "        alpha = F.softmax(nodes.mailbox['e'], dim=1).to(device = device)\n",
        "        \n",
        "        # equation (4)\n",
        "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1).to(device = device)\n",
        "        return {'h': h}\n",
        "\n",
        "    def forward(self, h):\n",
        "        # equation (1)\n",
        "        z = self.fc(h)\n",
        "        self.g.ndata['z'] = z\n",
        "        # equation (2)\n",
        "        self.g.apply_edges(self.edge_attention)\n",
        "        # equation (3) & (4)\n",
        "        self.g.update_all(self.message_func, self.reduce_func)\n",
        "        return self.g.ndata.pop('h')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Equation (1)\n",
        "\n",
        "$\\begin{align}z_i^{(l)}=W^{(l)}h_i^{(l)},(1)\\end{align}$\n",
        "\n",
        "The first one shows linear transformation. It's common and can be\n",
        "easily implemented in Pytorch using ``torch.nn.Linear``.\n",
        "\n",
        "Equation (2)\n",
        "\n",
        "$\\begin{align}e_{ij}^{(l)}=\\text{LeakyReLU}(\\vec a^{(l)^T}(z_i^{(l)}|z_j^{(l)})),(2)\\end{align}$\n",
        "\n",
        "The un-normalized attention score $e_{ij}$ is calculated using the\n",
        "embeddings of adjacent nodes $i$ and $j$. This suggests that the\n",
        "attention scores can be viewed as edge data, which can be calculated by the\n",
        "``apply_edges`` API. The argument to the ``apply_edges`` is an **Edge UDF**,\n",
        "which is defined as below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def edge_attention(self, edges):\n",
        "    # edge UDF for equation (2)\n",
        "    z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
        "    a = self.attn_fc(z2)\n",
        "    return {'e' : F.leaky_relu(a)}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, the dot product with the learnable weight vector $\\vec{a^{(l)}}$\n",
        "is implemented again using PyTorch's linear transformation ``attn_fc``. Note\n",
        "that ``apply_edges`` will **batch** all the edge data in one tensor, so the\n",
        "``cat``, ``attn_fc`` here are applied on all the edges in parallel.\n",
        "\n",
        "Equation (3) & (4)\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "  \\alpha_{ij}^{(l)}&=\\frac{\\exp(e_{ij}^{(l)})}{\\sum_{k\\in \\mathcal{N}(i)}^{}\\exp(e_{ik}^{(l)})},(3)\\\\\n",
        "  h_i^{(l+1)}&=\\sigma\\left(\\sum_{j\\in \\mathcal{N}(i)} {\\alpha^{(l)}_{ij} z^{(l)}_j }\\right),(4)\n",
        "  \\end{align}\n",
        "\n",
        "Similar to GCN, ``update_all`` API is used to trigger message passing on all\n",
        "the nodes. The message function sends out two tensors: the transformed ``z``\n",
        "embedding of the source node and the un-normalized attention score ``e`` on\n",
        "each edge. The reduce function then performs two tasks:\n",
        "\n",
        "\n",
        "* Normalize the attention scores using softmax (equation (3)).\n",
        "* Aggregate neighbor embeddings weighted by the attention scores (equation(4)).\n",
        "\n",
        "Both tasks first fetch data from the mailbox and then manipulate it on the\n",
        "second dimension (``dim=1``), on which the messages are batched.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def reduce_func(self, nodes):\n",
        "    # reduce UDF for equation (3) & (4)\n",
        "    # equation (3)\n",
        "    alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
        "    # equation (4)\n",
        "    h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
        "    return {'h' : h}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi-head attention\n",
        "\n",
        "Analogous to multiple channels in ConvNet, GAT introduces **multi-head\n",
        "attention** to enrich the model capacity and to stabilize the learning\n",
        "process. Each attention head has its own parameters and their outputs can be\n",
        "merged in two ways:\n",
        "\n",
        "$$\\begin{align}\\text{concatenation}: h^{(l+1)}_{i} =||_{k=1}^{K}\\sigma\\left(\\sum_{j\\in \\mathcal{N}(i)}\\alpha_{ij}^{k}W^{k}h^{(l)}_{j}\\right)\\end{align}$$\n",
        "\n",
        "or\n",
        "\n",
        "$$\\begin{align}\\text{average}: h_{i}^{(l+1)}=\\sigma\\left(\\frac{1}{K}\\sum_{k=1}^{K}\\sum_{j\\in\\mathcal{N}(i)}\\alpha_{ij}^{k}W^{k}h^{(l)}_{j}\\right)\\end{align}$$\n",
        "\n",
        "where $K$ is the number of heads. You can use\n",
        "concatenation for intermediary layers and average for the final layer.\n",
        "\n",
        "Use the above defined single-head ``GATLayer`` as the building block\n",
        "for the ``MultiHeadGATLayer`` below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MultiHeadGATLayer(nn.Module):\n",
        "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
        "        super(MultiHeadGATLayer, self).__init__()\n",
        "        self.heads = nn.ModuleList()\n",
        "        for i in range(num_heads):\n",
        "            self.heads.append(GATLayer(g, in_dim, out_dim).to(device= device))\n",
        "        self.merge = merge\n",
        "\n",
        "    def forward(self, h):\n",
        "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
        "        if self.merge == 'cat':\n",
        "            # concat on the output feature dimension (dim=1)\n",
        "            return torch.cat(head_outs, dim=1)\n",
        "        else:\n",
        "            # merge using average\n",
        "            return torch.mean(torch.stack(head_outs))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Put everything together\n",
        "\n",
        "\n",
        "Now, you can define a two-layer GAT model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GAT(nn.Module):\n",
        "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
        "        super(GAT, self).__init__()\n",
        "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads).to(device)\n",
        "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
        "        # multiple head outputs are concatenated together. Also, only\n",
        "        # one attention head in the output layer.\n",
        "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1).to(device)\n",
        "\n",
        "    def forward(self, h):\n",
        "        h = self.layer1(h)\n",
        "        h = F.elu(h)\n",
        "        h = self.layer2(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graph(num_nodes=11352, num_edges=62459,\n",
              "      ndata_schemes={'active': Scheme(shape=(10,), dtype=torch.float64), 'label': Scheme(shape=(), dtype=torch.int32), 'feature': Scheme(shape=(25,), dtype=torch.float64)}\n",
              "      edata_schemes={})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_list = Load_GraphList()\n",
        "graph_list[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color=\"pink\"> *Isolated Vertex* </font>\n",
        "\n",
        "1. *Selecting Top 10 degrees of Vertex from Base graph $ U:=\\{u_1, ..., u_{10}\\}$*\n",
        "2. *for $v \\in V_{isolated} :$*\n",
        "   *    *$(v, Random(U)) := 1$*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "random_edge/tweet 1/6 hr/second/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 4: 100%|██████████| 150/150 [01:21<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 8: 100%|██████████| 150/150 [01:21<00:00,  1.84it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/6 hr/third/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 3: 100%|██████████| 150/150 [01:21<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 5: 100%|██████████| 150/150 [01:21<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/first/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 7: 100%|██████████| 150/150 [01:21<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/second/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 1: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 5: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/8 hr/third/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 1: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/first/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 3: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 4: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 5: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 9: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/second/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 5: 100%|██████████| 150/150 [01:23<00:00,  1.79it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/10 hr/third/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 8: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/first/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 1: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 2: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 4: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 5: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 8: 100%|██████████| 150/150 [01:23<00:00,  1.79it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 9: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/second/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/12 hr/third/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 3: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 4: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 5: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/first/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 2: 100%|██████████| 150/150 [01:23<00:00,  1.79it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 3: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 8: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 9: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/second/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 2: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/16 hr/third/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 1: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 3: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 4: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/first/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 4: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 9: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/20 hr/second/Batch 10: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 1: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 2: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/20 hr/third/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 1: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 2: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 8: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/first/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.83it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 5: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 6: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 7: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 8: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/second/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 1: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 2: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 3: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 4: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 5: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 6: 100%|██████████| 150/150 [01:23<00:00,  1.80it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 7: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 8: 100%|██████████| 150/150 [01:22<00:00,  1.82it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 9: 100%|██████████| 150/150 [01:22<00:00,  1.81it/s]\n",
            "random_edge/tweet 1/24 hr/third/Batch 10: 100%|██████████| 150/150 [01:23<00:00,  1.81it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 1: 100%|██████████| 150/150 [00:53<00:00,  2.80it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 2: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 3: 100%|██████████| 150/150 [00:52<00:00,  2.84it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 5: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 7: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 8: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 9: 100%|██████████| 150/150 [00:54<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/1 hr/first/Batch 10: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 1: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 3: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 4: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 5: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 6: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 7: 100%|██████████| 150/150 [00:55<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 8: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 9: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/1 hr/second/Batch 10: 100%|██████████| 150/150 [00:52<00:00,  2.86it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 1: 100%|██████████| 150/150 [00:56<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 3: 100%|██████████| 150/150 [00:52<00:00,  2.88it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 5: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 6: 100%|██████████| 150/150 [00:53<00:00,  2.79it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 7: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 8: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 9: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/1 hr/third/Batch 10: 100%|██████████| 150/150 [00:58<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 3: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 4: 100%|██████████| 150/150 [00:53<00:00,  2.80it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 5: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 6: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 7: 100%|██████████| 150/150 [00:56<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 8: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 9: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/2 hr/first/Batch 10: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 1: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 3: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 4: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 5: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 6: 100%|██████████| 150/150 [00:52<00:00,  2.83it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 7: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 8: 100%|██████████| 150/150 [01:02<00:00,  2.41it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 9: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/2 hr/second/Batch 10: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 1: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 3: 100%|██████████| 150/150 [00:53<00:00,  2.81it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 4: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 5: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 6: 100%|██████████| 150/150 [00:52<00:00,  2.85it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 7: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 8: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 9: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/2 hr/third/Batch 10: 100%|██████████| 150/150 [00:54<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 2: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 3: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 4: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 5: 100%|██████████| 150/150 [00:52<00:00,  2.87it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.78it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 7: 100%|██████████| 150/150 [00:56<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 8: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 9: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/4 hr/first/Batch 10: 100%|██████████| 150/150 [00:53<00:00,  2.78it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 1: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 2: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 3: 100%|██████████| 150/150 [00:53<00:00,  2.82it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 4: 100%|██████████| 150/150 [00:53<00:00,  2.83it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 5: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 7: 100%|██████████| 150/150 [00:53<00:00,  2.80it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 8: 100%|██████████| 150/150 [00:52<00:00,  2.88it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 9: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/4 hr/second/Batch 10: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 1: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 2: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 3: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 4: 100%|██████████| 150/150 [00:53<00:00,  2.78it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 5: 100%|██████████| 150/150 [00:57<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 6: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 7: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 8: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 9: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/4 hr/third/Batch 10: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 1: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 3: 100%|██████████| 150/150 [00:55<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 4: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 5: 100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 7: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 8: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 9: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/6 hr/first/Batch 10: 100%|██████████| 150/150 [00:53<00:00,  2.81it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 3: 100%|██████████| 150/150 [00:56<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 5: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 6: 100%|██████████| 150/150 [00:59<00:00,  2.53it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 7: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 8: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 9: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/6 hr/second/Batch 10: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 1: 100%|██████████| 150/150 [00:56<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 3: 100%|██████████| 150/150 [00:53<00:00,  2.79it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 5: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 6: 100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 7: 100%|██████████| 150/150 [00:52<00:00,  2.84it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 8: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 9: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/6 hr/third/Batch 10: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 1: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 2: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 3: 100%|██████████| 150/150 [00:53<00:00,  2.80it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 4: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 5: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 7: 100%|██████████| 150/150 [00:50<00:00,  2.99it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 8: 100%|██████████| 150/150 [00:54<00:00,  2.78it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 9: 100%|██████████| 150/150 [00:53<00:00,  2.80it/s]\n",
            "random_edge/tweet 3/8 hr/first/Batch 10: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 1: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 2: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 3: 100%|██████████| 150/150 [00:55<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 4: 100%|██████████| 150/150 [01:00<00:00,  2.49it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 5: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 7: 100%|██████████| 150/150 [00:56<00:00,  2.67it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 8: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 9: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/8 hr/second/Batch 10: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 1: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 2: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 3: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 4: 100%|██████████| 150/150 [00:59<00:00,  2.52it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 5: 100%|██████████| 150/150 [00:59<00:00,  2.50it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 6: 100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 7: 100%|██████████| 150/150 [00:53<00:00,  2.78it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 8: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 9: 100%|██████████| 150/150 [00:54<00:00,  2.76it/s]\n",
            "random_edge/tweet 3/8 hr/third/Batch 10: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 1: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 3: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 4: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 5: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 7: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 8: 100%|██████████| 150/150 [01:00<00:00,  2.49it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 9: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/10 hr/first/Batch 10: 100%|██████████| 150/150 [01:00<00:00,  2.49it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 1: 100%|██████████| 150/150 [01:02<00:00,  2.42it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 3: 100%|██████████| 150/150 [00:56<00:00,  2.67it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 4: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 5: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 7: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 8: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 9: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/10 hr/second/Batch 10: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 2: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 3: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 4: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 5: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 7: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 8: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 9: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/10 hr/third/Batch 10: 100%|██████████| 150/150 [01:01<00:00,  2.45it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 1: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 3: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 4: 100%|██████████| 150/150 [00:56<00:00,  2.67it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 5: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 6: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 7: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 8: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 9: 100%|██████████| 150/150 [00:59<00:00,  2.52it/s]\n",
            "random_edge/tweet 3/12 hr/first/Batch 10: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 1: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 2: 100%|██████████| 150/150 [01:01<00:00,  2.45it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 3: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 4: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 5: 100%|██████████| 150/150 [00:52<00:00,  2.85it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 7: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 8: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 9: 100%|██████████| 150/150 [00:55<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/12 hr/second/Batch 10: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 3: 100%|██████████| 150/150 [00:58<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 4: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 5: 100%|██████████| 150/150 [00:52<00:00,  2.88it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 6: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 7: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 8: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 9: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/12 hr/third/Batch 10: 100%|██████████| 150/150 [00:57<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 3: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 4: 100%|██████████| 150/150 [00:55<00:00,  2.71it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 5: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 6: 100%|██████████| 150/150 [00:59<00:00,  2.52it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 7: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 8: 100%|██████████| 150/150 [01:00<00:00,  2.46it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 9: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/16 hr/first/Batch 10: 100%|██████████| 150/150 [00:56<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 1: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 2: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 3: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 4: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 5: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 7: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 8: 100%|██████████| 150/150 [01:01<00:00,  2.46it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 9: 100%|██████████| 150/150 [00:53<00:00,  2.82it/s]\n",
            "random_edge/tweet 3/16 hr/second/Batch 10: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 1: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 3: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 4: 100%|██████████| 150/150 [00:53<00:00,  2.78it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 5: 100%|██████████| 150/150 [00:53<00:00,  2.81it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 7: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 8: 100%|██████████| 150/150 [00:53<00:00,  2.80it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 9: 100%|██████████| 150/150 [01:03<00:00,  2.35it/s]\n",
            "random_edge/tweet 3/16 hr/third/Batch 10: 100%|██████████| 150/150 [00:54<00:00,  2.75it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 2: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 3: 100%|██████████| 150/150 [00:57<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 4: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 5: 100%|██████████| 150/150 [00:55<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 7: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 8: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 9: 100%|██████████| 150/150 [00:57<00:00,  2.62it/s]\n",
            "random_edge/tweet 3/20 hr/first/Batch 10: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 1: 100%|██████████| 150/150 [00:54<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 2: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 3: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 4: 100%|██████████| 150/150 [01:03<00:00,  2.38it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 5: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 7: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 8: 100%|██████████| 150/150 [00:56<00:00,  2.64it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 9: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/20 hr/second/Batch 10: 100%|██████████| 150/150 [01:00<00:00,  2.48it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 2: 100%|██████████| 150/150 [00:53<00:00,  2.81it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 3: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 4: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 5: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 6: 100%|██████████| 150/150 [00:59<00:00,  2.52it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 7: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 8: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 9: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/20 hr/third/Batch 10: 100%|██████████| 150/150 [01:01<00:00,  2.45it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 1: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 2: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 3: 100%|██████████| 150/150 [00:53<00:00,  2.83it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 4: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 5: 100%|██████████| 150/150 [00:59<00:00,  2.51it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 7: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 8: 100%|██████████| 150/150 [00:55<00:00,  2.70it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 9: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/24 hr/first/Batch 10: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 3: 100%|██████████| 150/150 [01:00<00:00,  2.47it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 5: 100%|██████████| 150/150 [00:54<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 6: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 7: 100%|██████████| 150/150 [00:58<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 8: 100%|██████████| 150/150 [00:55<00:00,  2.73it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 9: 100%|██████████| 150/150 [00:57<00:00,  2.61it/s]\n",
            "random_edge/tweet 3/24 hr/second/Batch 10: 100%|██████████| 150/150 [00:58<00:00,  2.55it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 1: 100%|██████████| 150/150 [00:57<00:00,  2.59it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 2: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 3: 100%|██████████| 150/150 [01:01<00:00,  2.44it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 5: 100%|██████████| 150/150 [00:57<00:00,  2.60it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 6: 100%|██████████| 150/150 [00:54<00:00,  2.74it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 7: 100%|██████████| 150/150 [00:56<00:00,  2.65it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 8: 100%|██████████| 150/150 [00:58<00:00,  2.58it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 9: 100%|██████████| 150/150 [00:56<00:00,  2.66it/s]\n",
            "random_edge/tweet 3/24 hr/third/Batch 10: 100%|██████████| 150/150 [00:54<00:00,  2.77it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 1: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 2: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 3: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 4: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 6: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 7: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 8: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 9: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "random_edge/tweet 5/1 hr/first/Batch 10: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 1: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 2: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 3: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 4: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 7: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 8: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 9: 100%|██████████| 150/150 [01:10<00:00,  2.14it/s]\n",
            "random_edge/tweet 5/1 hr/second/Batch 10: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 1: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 2: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 3: 100%|██████████| 150/150 [01:14<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 4: 100%|██████████| 150/150 [01:08<00:00,  2.19it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 5: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 6: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 7: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 8: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 9: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/1 hr/third/Batch 10: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 1: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 2: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 3: 100%|██████████| 150/150 [01:11<00:00,  2.11it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 4: 100%|██████████| 150/150 [01:12<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 5: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 6: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 7: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 8: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 9: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/2 hr/first/Batch 10: 100%|██████████| 150/150 [01:10<00:00,  2.13it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 1: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 2: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 3: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 4: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 7: 100%|██████████| 150/150 [01:14<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 8: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 9: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/2 hr/second/Batch 10: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 1: 100%|██████████| 150/150 [01:11<00:00,  2.09it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 2: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 3: 100%|██████████| 150/150 [01:11<00:00,  2.11it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 4: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 5: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 7: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 8: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 9: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/2 hr/third/Batch 10: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 1: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 2: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 3: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 5: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 6: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 7: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 8: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 9: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/4 hr/first/Batch 10: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 1: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 2: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 3: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 5: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 6: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 7: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 8: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 9: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "random_edge/tweet 5/4 hr/second/Batch 10: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 1: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 2: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 3: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 4: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 5: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 7: 100%|██████████| 150/150 [01:10<00:00,  2.12it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 8: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 9: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/4 hr/third/Batch 10: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 1: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 3: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 4: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 5: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 6: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 7: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 8: 100%|██████████| 150/150 [01:11<00:00,  2.11it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 9: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/6 hr/first/Batch 10: 100%|██████████| 150/150 [01:12<00:00,  2.06it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 1: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 3: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 5: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 6: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 7: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 8: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 9: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/6 hr/second/Batch 10: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 1: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 2: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 3: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 4: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 5: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 6: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 7: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 8: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 9: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/6 hr/third/Batch 10: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 1: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 2: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 3: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 4: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 5: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 6: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 7: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 8: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 9: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/8 hr/first/Batch 10: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 1: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 2: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 3: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 4: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 5: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 7: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 8: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 9: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/8 hr/second/Batch 10: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 1: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 2: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 3: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 4: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 5: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 6: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 7: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 8: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 9: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/8 hr/third/Batch 10: 100%|██████████| 150/150 [01:14<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 1: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 2: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 3: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 4: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 6: 100%|██████████| 150/150 [01:20<00:00,  1.86it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 7: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 8: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 9: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/10 hr/first/Batch 10: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 1: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 2: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 3: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 4: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 6: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 7: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 8: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 9: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/10 hr/second/Batch 10: 100%|██████████| 150/150 [01:10<00:00,  2.11it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 1: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 3: 100%|██████████| 150/150 [01:20<00:00,  1.86it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 4: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 5: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 6: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 7: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 8: 100%|██████████| 150/150 [01:19<00:00,  1.89it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 9: 100%|██████████| 150/150 [01:11<00:00,  2.10it/s]\n",
            "random_edge/tweet 5/10 hr/third/Batch 10: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 1: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 2: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 3: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 4: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 5: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 6: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 7: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 8: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 9: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/12 hr/first/Batch 10: 100%|██████████| 150/150 [01:21<00:00,  1.85it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 1: 100%|██████████| 150/150 [01:09<00:00,  2.15it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 3: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 5: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 6: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 7: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 8: 100%|██████████| 150/150 [01:12<00:00,  2.08it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 9: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/12 hr/second/Batch 10: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 1: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 2: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 3: 100%|██████████| 150/150 [01:19<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 5: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 6: 100%|██████████| 150/150 [01:14<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 7: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 8: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 9: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/12 hr/third/Batch 10: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 1: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 3: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 4: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 6: 100%|██████████| 150/150 [01:14<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 7: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 8: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 9: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/first/Batch 10: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 1: 100%|██████████| 150/150 [01:17<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 2: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 3: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 5: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 6: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 7: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 8: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 9: 100%|██████████| 150/150 [01:19<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/16 hr/second/Batch 10: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 1: 100%|██████████| 150/150 [01:19<00:00,  1.89it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 2: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 3: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 5: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 7: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 8: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 9: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/16 hr/third/Batch 10: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 1: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 2: 100%|██████████| 150/150 [01:19<00:00,  1.88it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 3: 100%|██████████| 150/150 [01:19<00:00,  1.88it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 4: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 5: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 6: 100%|██████████| 150/150 [01:13<00:00,  2.05it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 7: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 8: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 9: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/20 hr/first/Batch 10: 100%|██████████| 150/150 [01:17<00:00,  1.93it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 1: 100%|██████████| 150/150 [01:12<00:00,  2.07it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 2: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 3: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 4: 100%|██████████| 150/150 [01:21<00:00,  1.84it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 5: 100%|██████████| 150/150 [01:18<00:00,  1.92it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 6: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 7: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 8: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 9: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/20 hr/second/Batch 10: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 1: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 3: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 4: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 5: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 6: 100%|██████████| 150/150 [01:14<00:00,  2.02it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 7: 100%|██████████| 150/150 [01:16<00:00,  1.96it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 8: 100%|██████████| 150/150 [01:19<00:00,  1.88it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 9: 100%|██████████| 150/150 [01:15<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/20 hr/third/Batch 10: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 1: 100%|██████████| 150/150 [01:16<00:00,  1.97it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 2: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 3: 100%|██████████| 150/150 [01:14<00:00,  2.00it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 4: 100%|██████████| 150/150 [01:13<00:00,  2.03it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 5: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 6: 100%|██████████| 150/150 [01:18<00:00,  1.91it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 7: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 8: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 9: 100%|██████████| 150/150 [01:16<00:00,  1.95it/s]\n",
            "random_edge/tweet 5/24 hr/first/Batch 10: 100%|██████████| 150/150 [01:13<00:00,  2.04it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 1: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 2: 100%|██████████| 150/150 [01:17<00:00,  1.94it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 3: 100%|██████████| 150/150 [01:18<00:00,  1.90it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 4: 100%|██████████| 150/150 [01:14<00:00,  2.01it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 5: 100%|██████████| 150/150 [01:15<00:00,  1.99it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 6: 100%|██████████| 150/150 [01:21<00:00,  1.85it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 7: 100%|██████████| 150/150 [01:15<00:00,  1.98it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 8: 100%|██████████| 150/150 [01:08<00:00,  2.20it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 9: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 5/24 hr/second/Batch 10: 100%|██████████| 150/150 [00:55<00:00,  2.69it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 1: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 2: 100%|██████████| 150/150 [00:55<00:00,  2.68it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 3: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 4: 100%|██████████| 150/150 [00:57<00:00,  2.63it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 5: 100%|██████████| 150/150 [00:58<00:00,  2.56it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 6: 100%|██████████| 150/150 [00:58<00:00,  2.57it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 7: 100%|██████████| 150/150 [00:59<00:00,  2.54it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 8: 100%|██████████| 150/150 [00:53<00:00,  2.82it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 9: 100%|██████████| 150/150 [00:55<00:00,  2.72it/s]\n",
            "random_edge/tweet 5/24 hr/third/Batch 10: 100%|██████████| 150/150 [00:56<00:00,  2.67it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "t = [1, 2, 4, 6, 8, 10, 12, 16, 20, 24]\n",
        "tweet_list = [1, 3, 5]\n",
        "graph_list = [graph_list[i-1] for i in tweet_list]\n",
        "metrics = evaluation()\n",
        "\n",
        "for g, tweet_id in zip(graph_list, tweet_list):\n",
        "    \n",
        "    active_matrix = g.ndata['active']\n",
        "    labels = g.ndata['label']\n",
        "    features = g.ndata['feature']\n",
        "    folder = 'random_edge/tweet %d/' % tweet_id\n",
        "    run_time = ['first/', 'second/', 'third/']\n",
        "\n",
        "    for h in range(10): # time stamp\n",
        "        for times in run_time:\n",
        "\n",
        "            # Selecting Inactive users to train and test => 1:9\n",
        "            active_vec = deepcopy(active_matrix[:, h])\n",
        "            active_user = (active_vec == 1).nonzero().flatten().tolist()\n",
        "            inactive_user = (active_vec == 0).nonzero().flatten().tolist()\n",
        "\n",
        "            # chunk inactive users into 10 batch\n",
        "            batch = shuffle_chunks(input= inactive_user, batch_num= 10)\n",
        "\n",
        "            time_path = folder + '%d hr/' % t[h]\n",
        "            time_path += times\n",
        "\n",
        "            \n",
        "            # Selecting test and train set      \n",
        "            for i in range(10):\n",
        "                    \n",
        "                f = open(time_path + 'Batch %d.txt' % (i+1), 'a')\n",
        "                print('Active user   :', len(active_user), file= f)\n",
        "                print('Inactive user :', len(inactive_user), file= f)\n",
        "\n",
        "                test_idx = i\n",
        "                train_idx = [j for j in range(10) if j!= i]\n",
        "                test_set = deepcopy(batch[i])\n",
        "                train_set = deepcopy(active_user)\n",
        "                for idx in train_idx:\n",
        "                    train_set += deepcopy(batch[idx])\n",
        "\n",
        "                test_p, test_n = PN_split(ind= test_set, label= labels)\n",
        "\n",
        "                print('Test || P: %d || N: %d' % (len(test_p), len(test_n)), file= f)\n",
        "\n",
        "                # find Positive and Negative samples from training set\n",
        "                p, n = PN_split(ind= train_set, label= labels)\n",
        "\n",
        "                print('Train before NS || P: %d || N: %d' % (len(p), len(n)), file= f)\n",
        "\n",
        "                # Negative Sampling\n",
        "                NS = Negative_Sampling(pos_sample= p, neg_samples= n)\n",
        "                train_set = deepcopy(NS) + deepcopy(p)\n",
        "\n",
        "                print('Train after NS || P: %d || N: %d' % (len(p), len(NS)), file= f)\n",
        "\n",
        "                nodes = deepcopy(train_set) + deepcopy(test_set)\n",
        "                nodes = sorted(nodes)\n",
        "                delete_node = set(n) - set(NS)\n",
        "                delete_node = list(delete_node)\n",
        "\n",
        "                # process data graph\n",
        "                data_g, datag_f, datag_label, datag_active, iso_d = Data_Graph_Process(\n",
        "                    del_nodes= delete_node, nodes_set= nodes,\n",
        "                    g= g, feature= features, active_matrix= active_matrix, label= labels\n",
        "                )\n",
        "                datag_f = torch.concat((datag_f, datag_active[:, 0:h+1]), dim=1)\n",
        "                datag_f = F.normalize(datag_f)\n",
        "                print('To GAT:', file= f)\n",
        "                print('   nodes :', data_g.num_nodes(), file= f)\n",
        "                print('   edges :', data_g.num_edges(), file= f)\n",
        "                print('   Isolated :', len(iso_d), file= f)\n",
        "                \n",
        "\n",
        "                # Train, Test mask\n",
        "                train_mask, test_mask = train_test_split(train_set= train_set, test_set= test_set, nodes= nodes)\n",
        "\n",
        "                # run model\n",
        "                net = GAT(data_g.to(device= device),\n",
        "                    in_dim=datag_f.size()[1],\n",
        "                    hidden_dim=8,\n",
        "                    out_dim=2, # Class number\n",
        "                    num_heads=3)\n",
        "                \n",
        "                # create optimizer\n",
        "                optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "                x = list()\n",
        "                y = list()\n",
        "                train_res = list()\n",
        "                test_res = list()\n",
        "                for epoch in tqdm(range(150), total=150, desc = time_path + 'Batch %d' % (i+1)):\n",
        "                    t0 = time.time()\n",
        "\n",
        "                    logits = net(datag_f.float().to(device))\n",
        "                    logp = F.log_softmax(logits, 1) # shape = |V| * classes\n",
        "                    loss = F.nll_loss(logp[train_mask].to(device), datag_label[train_mask].to(device))\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    \n",
        "                    print('=' * 80, file= f)\n",
        "                    print(\"epoch {} | loss: {:.5f} | runtime: {:.2f}(s)\".format(epoch, loss.item(), time.time() - t0), file= f)\n",
        "                    x.append(epoch)\n",
        "                    y.append(loss.item())\n",
        "\n",
        "                    tp, tn, fp, fn = metrics.confusion_matrix(logits= logits, labels= datag_label, mask= test_mask)\n",
        "                    print('  Test: ', file= f)\n",
        "                    confusion_to_file(tp, tn, fp, fn, f)\n",
        "                    test_res.append([epoch, loss.item(), tp, tn, fp, fn])\n",
        "                \n",
        "                write_to_pd(test_res, time_path, i+1)\n",
        "                plotting(x, y, time_path, 'Batch %d' % (i+1))\n",
        "                f.close()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pick tweet count least, mid, last 3 tweet, run their 10 time steps, \n",
        "draw excel output template"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing and understanding attention learned\n",
        "----------------------------------------------\n",
        "\n",
        "Cora\n",
        "\n",
        "The following table summarizes the model performance on Cora that is reported in\n",
        "`the GAT paper <https://arxiv.org/pdf/1710.10903.pdf>`_ and obtained with DGL \n",
        "implementations.\n",
        "\n",
        ".. list-table::\n",
        "   :header-rows: 1\n",
        "\n",
        "   * - Model\n",
        "     - Accuracy\n",
        "   * - GCN (paper)\n",
        "     - $81.4\\pm 0.5%$\n",
        "   * - GCN (dgl)\n",
        "     - $82.05\\pm 0.33%$\n",
        "   * - GAT (paper)\n",
        "     - $83.0\\pm 0.7%$\n",
        "   * - GAT (dgl)\n",
        "     - $83.69\\pm 0.529%$\n",
        "\n",
        "*What kind of attention distribution has our model learned?*\n",
        "\n",
        "Because the attention weight $a_{ij}$ is associated with edges, you can\n",
        "visualize it by coloring edges. Below you can pick a subgraph of Cora and plot the\n",
        "attention weights of the last ``GATLayer``. The nodes are colored according\n",
        "to their labels, whereas the edges are colored according to the magnitude of\n",
        "the attention weights, which can be referred with the colorbar on the right.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/gat/cora-attention.png)\n",
        "\n",
        "\n",
        "You can see that the model seems to learn different attention weights. To\n",
        "understand the distribution more thoroughly, measure the `entropy\n",
        "<https://en.wikipedia.org/wiki/Entropy_(information_theory>`_) of the\n",
        "attention distribution. For any node $i$,\n",
        "$\\{\\alpha_{ij}\\}_{j\\in\\mathcal{N}(i)}$ forms a discrete probability\n",
        "distribution over all its neighbors with the entropy given by\n",
        "\n",
        "$\\begin{align}H({\\alpha_{ij}}_{j\\in\\mathcal{N}(i)})=-\\sum_{j\\in\\mathcal{N}(i)} \\alpha_{ij}\\log\\alpha_{ij}\\end{align}$\n",
        "\n",
        "A low entropy means a high degree of concentration, and vice\n",
        "versa. An entropy of 0 means all attention is on one source node. The uniform\n",
        "distribution has the highest entropy of $ log(\\mathcal{N}(i)) $.\n",
        "Ideally, you want to see the model learns a distribution of lower entropy\n",
        "(i.e, one or two neighbors are much more important than the others).\n",
        "\n",
        "Note that since nodes can have different degrees, the maximum entropy will\n",
        "also be different. Therefore, you plot the aggregated histogram of entropy\n",
        "values of all nodes in the entire graph. Below are the attention histogram of\n",
        "learned by each attention head.\n",
        "\n",
        "|image2|\n",
        "\n",
        "As a reference, here is the histogram if all the nodes have uniform attention weight distribution.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/gat/cora-attention-uniform-hist.png)\n",
        "\n",
        "\n",
        "One can see that **the attention values learned is quite similar to uniform distribution**\n",
        "(i.e, all neighbors are equally important). This partially\n",
        "explains why the performance of GAT is close to that of GCN on Cora\n",
        "(according to `author's reported result\n",
        "<https://arxiv.org/pdf/1710.10903.pdf>`_, the accuracy difference averaged\n",
        "over 100 runs is less than 2 percent). Attention does not matter\n",
        "since it does not differentiate much.\n",
        "\n",
        "*Does that mean the attention mechanism is not useful?* No! A different\n",
        "dataset exhibits an entirely different pattern, as you can see next.\n",
        "\n",
        "Protein-protein interaction (PPI) networks\n",
        "\n",
        "The PPI dataset used here consists of $24$ graphs corresponding to\n",
        "different human tissues. Nodes can have up to $121$ kinds of labels, so\n",
        "the label of node is represented as a binary tensor of size $121$. The\n",
        "task is to predict node label.\n",
        "\n",
        "Use $20$ graphs for training, $2$ for validation and $2$\n",
        "for test. The average number of nodes per graph is $2372$. Each node\n",
        "has $50$ features that are composed of positional gene sets, motif gene\n",
        "sets, and immunological signatures. Critically, test graphs remain completely\n",
        "unobserved during training, a setting called \"inductive learning\".\n",
        "\n",
        "Compare the performance of GAT and GCN for $10$ random runs on this\n",
        "task and use hyperparameter search on the validation set to find the best\n",
        "model.\n",
        "\n",
        ".. list-table::\n",
        "   :header-rows: 1\n",
        "\n",
        "   * - Model\n",
        "     - F1 Score(micro)\n",
        "   * - GAT\n",
        "     - $0.975 \\pm 0.006$\n",
        "   * - GCN\n",
        "     - $0.509 \\pm 0.025$\n",
        "   * - Paper\n",
        "     - $0.973 \\pm 0.002$\n",
        "\n",
        "The table above is the result of this experiment, where you use micro `F1\n",
        "score <https://en.wikipedia.org/wiki/F1_score>`_ to evaluate the model\n",
        "performance.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Below is the calculation process of F1 score:\n",
        "\n",
        "\n",
        "  * $precision=\\frac{\\sum_{t=1}^{n}TP_{t}}{\\sum_{t=1}^{n}(TP_{t} +FP_{t})}$\n",
        "\n",
        "  * $recall=\\frac{\\sum_{t=1}^{n}TP_{t}}{\\sum_{t=1}^{n}(TP_{t} +FN_{t})}$\n",
        "\n",
        "  * $F1_{micro}=2\\frac{precision*recall}{precision+recall}$\n",
        "\n",
        "  * $TP_{t}$ represents for number of nodes that both have and are predicted to have label $t$\n",
        "  * $FP_{t}$ represents for number of nodes that do not have but are predicted to have label $t$\n",
        "  * $FN_{t}$ represents for number of output classes labeled as $t$ but predicted as others.\n",
        "  * $n$ is the number of labels, i.e. $121$ in our case.</p></div>\n",
        "\n",
        "During training, use ``BCEWithLogitsLoss`` as the loss function. The\n",
        "learning curves of GAT and GCN are presented below; what is evident is the\n",
        "dramatic performance adavantage of GAT over GCN.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/gat/ppi-curve.png)\n",
        "\n",
        "  :width: 300px\n",
        "  :align: center\n",
        "\n",
        "As before, you can have a statistical understanding of the attentions learned\n",
        "by showing the histogram plot for the node-wise attention entropy. Below are\n",
        "the attention histograms learned by different attention layers.\n",
        "\n",
        "*Attention learned in layer 1:*\n",
        "\n",
        "|image5|\n",
        "\n",
        "*Attention learned in layer 2:*\n",
        "\n",
        "|image6|\n",
        "\n",
        "*Attention learned in final layer:*\n",
        "\n",
        "|image7|\n",
        "\n",
        "Again, comparing with uniform distribution: \n",
        "\n",
        "![](https://data.dgl.ai/tutorial/gat/ppi-uniform-hist.png)\n",
        "\n",
        "  :width: 250px\n",
        "  :align: center\n",
        "\n",
        "Clearly, **GAT does learn sharp attention weights**! There is a clear pattern\n",
        "over the layers as well: **the attention gets sharper with a higher\n",
        "layer**.\n",
        "\n",
        "Unlike the Cora dataset where GAT's gain is minimal at best, for PPI there\n",
        "is a significant performance gap between GAT and other GNN variants compared\n",
        "in `the GAT paper <https://arxiv.org/pdf/1710.10903.pdf>`_ (at least 20 percent),\n",
        "and the attention distributions between the two clearly differ. While this\n",
        "deserves further research, one immediate conclusion is that GAT's advantage\n",
        "lies perhaps more in its ability to handle a graph with more complex\n",
        "neighborhood structure.\n",
        "\n",
        "What's next?\n",
        "------------\n",
        "\n",
        "So far, you have seen how to use DGL to implement GAT. There are some\n",
        "missing details such as dropout, skip connections, and hyper-parameter tuning,\n",
        "which are practices that do not involve DGL-related concepts. For more information\n",
        "check out the full example.\n",
        "\n",
        "* See the optimized `full example <https://github.com/dmlc/dgl/blob/master/examples/pytorch/gat/gat.py>`_.\n",
        "* The next tutorial describes how to speedup GAT models by parallelizing multiple attention heads and SPMV optimization.\n",
        "\n",
        ".. |image2| image:: https://data.dgl.ai/tutorial/gat/cora-attention-hist.png\n",
        ".. |image5| image:: https://data.dgl.ai/tutorial/gat/ppi-first-layer-hist.png\n",
        ".. |image6| image:: https://data.dgl.ai/tutorial/gat/ppi-second-layer-hist.png\n",
        ".. |image7| image:: https://data.dgl.ai/tutorial/gat/ppi-final-layer-hist.png\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dgl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd41fe153378347448e1c201e7672b8e1a74a52b34c8d7e7e6593400a70fc6a0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
